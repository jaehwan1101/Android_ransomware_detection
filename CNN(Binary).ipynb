{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 폴더 경로 지정\n",
    "folder_path = r'C:\\Users\\pc\\Desktop\\CNN\\CIC-AndMal2017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charger 클래스의 샘플 개수: 39551\n",
      "Jisut 클래스의 샘플 개수: 25672\n",
      "Koler 클래스의 샘플 개수: 44555\n",
      "Lockerpin 클래스의 샘플 개수: 25307\n",
      "Pletor 클래스의 샘플 개수: 4715\n",
      "PornDroid 클래스의 샘플 개수: 46082\n",
      "RansomBO 클래스의 샘플 개수: 39859\n",
      "Simplocker 클래스의 샘플 개수: 36340\n",
      "SVpeng 클래스의 샘플 개수: 54161\n",
      "WannaLocker 클래스의 샘플 개수: 32701\n"
     ]
    }
   ],
   "source": [
    "# 랜섬웨어 클래스별 파일에 있는 샘플 개수를 확인하기 위한 딕셔너리\n",
    "samples_per_class = {}\n",
    "\n",
    "# Ransomware 폴더 내의 10개 폴더 경로 리스트 받아오기\n",
    "ransomware_folder_list = glob.glob(folder_path + '\\\\Ransomware\\\\*')\n",
    "\n",
    "# 모든 파일 로드 및 샘플 개수 확인\n",
    "for folder in ransomware_folder_list:\n",
    "    ransomware_class = folder.split('\\\\')[-1]  # 랜섬웨어 클래스명 추출\n",
    "\n",
    "    file_paths = glob.glob(folder + '\\\\*.csv')\n",
    "    total_samples = 0  # 클래스별 전체 샘플 개수 초기화\n",
    "    for file_path in file_paths:\n",
    "        data = pd.read_csv(file_path)\n",
    "        total_samples += data.shape[0]  # 데이터프레임의 행 수 / 샘플 개수 더하기\n",
    "\n",
    "    samples_per_class[ransomware_class] = total_samples\n",
    "\n",
    "# 클래스별 샘플 개수 출력\n",
    "for ransomware_class, num_samples in samples_per_class.items():\n",
    "    print(f\"{ransomware_class} 클래스의 샘플 개수: {num_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign_subset의 샘플 개수: 45000\n"
     ]
    }
   ],
   "source": [
    "benign_folder_path = r'C:\\Users\\pc\\Desktop\\CNN\\CIC-AndMal2017\\Benign'\n",
    "\n",
    "# 'Benign' 클래스의 파일 경로 리스트 받아오기\n",
    "benign_file_paths = glob.glob(benign_folder_path + '/*.csv')\n",
    "\n",
    "# 'Benign' 클래스의 데이터프레임 초기화\n",
    "benign_data = pd.DataFrame()\n",
    "\n",
    "# 'Benign' 클래스의 모든 파일 로드\n",
    "for file_path in benign_file_paths:\n",
    "    data = pd.read_csv(file_path)\n",
    "    benign_data = pd.concat([benign_data, data], ignore_index=True)\n",
    "\n",
    "# 'Benign' 클래스에서 45,000개 무작위 샘플 추출\n",
    "num_samples_benign = 45000\n",
    "if len(benign_data) > num_samples_benign:\n",
    "    benign_subset = benign_data.sample(n=num_samples_benign, random_state=42)\n",
    "else:\n",
    "    benign_subset = benign_data.copy()\n",
    "\n",
    "print(\"benign_subset의 샘플 개수:\", len(benign_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ransomware_subset의 샘플 개수: 45000\n"
     ]
    }
   ],
   "source": [
    "# 각 랜섬웨어 클래스별로 4,500개씩 무작위 샘플 추출 (비복원 추출)\n",
    "num_samples_per_ransomware_class = 4500\n",
    "all_ransomware_data = []\n",
    "\n",
    "# Ransomware 폴더 내의 10개 폴더 경로 리스트 받아오기\n",
    "ransomware_folder_list = glob.glob(folder_path + '\\\\Ransomware\\\\*')\n",
    "\n",
    "for ransomware_folder_path in ransomware_folder_list:\n",
    "    ransomware_file_paths = glob.glob(ransomware_folder_path + '/*.csv')\n",
    "    ransomware_data = pd.DataFrame()\n",
    "\n",
    "    # 각 랜섬웨어 클래스의 모든 파일 로드\n",
    "    for file_path in ransomware_file_paths:\n",
    "        data = pd.read_csv(file_path)\n",
    "        ransomware_data = pd.concat([ransomware_data, data], ignore_index=True)\n",
    "\n",
    "    # 랜섬웨어 클래스에서 4,500개 무작위 샘플 추출 (비복원 추출)\n",
    "    if len(ransomware_data) > num_samples_per_ransomware_class:\n",
    "        ransomware_subset = ransomware_data.sample(n=num_samples_per_ransomware_class, random_state=42, replace=False)\n",
    "    else:\n",
    "        ransomware_subset = ransomware_data.copy()\n",
    "    all_ransomware_data.append(ransomware_subset)\n",
    "\n",
    "# 모든 랜섬웨어 클래스의 데이터프레임들을 합치기\n",
    "all_ransomware_data = pd.concat(all_ransomware_data, ignore_index=True)\n",
    "\n",
    "print(\"ransomware_subset의 샘플 개수:\", len(all_ransomware_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 특성추출 데이터세트의 샘플 개수: 90000\n"
     ]
    }
   ],
   "source": [
    "# 'Benign' 클래스와 랜섬웨어 클래스의 데이터프레임들을 합치기\n",
    "sub_dataset = pd.concat([benign_subset, all_ransomware_data], ignore_index=True)\n",
    "\n",
    "print(\"최종 특성추출 데이터세트의 샘플 개수:\", len(sub_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선택된 특성들의 컬럼명:\n",
      "Index([' Source Port', ' Destination Port', ' Flow Duration',\n",
      "       'Total Length of Fwd Packets', ' Fwd Packet Length Max',\n",
      "       ' Bwd Packet Length Mean', ' Bwd Packet Length Std', ' Flow IAT Mean',\n",
      "       ' Flow IAT Max', ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean',\n",
      "       ' Fwd IAT Std', ' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Total',\n",
      "       ' Bwd IAT Max', 'Fwd PSH Flags', 'FIN Flag Count', ' SYN Flag Count',\n",
      "       ' PSH Flag Count', ' ACK Flag Count', ' URG Flag Count',\n",
      "       ' Avg Bwd Segment Size', ' Subflow Fwd Bytes', 'Init_Win_bytes_forward',\n",
      "       ' Init_Win_bytes_backward', ' act_data_pkt_fwd', 'Active Mean',\n",
      "       ' Active Std', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std',\n",
      "       ' Idle Max', ' Idle Min'],\n",
      "      dtype='object')\n",
      "\n",
      "최종 선택된 특성들의 데이터프레임:\n",
      "    Source Port   Destination Port   Flow Duration  \\\n",
      "0         38807                 53           95317   \n",
      "1         49679                 80          258421   \n",
      "2         36975                443        10246479   \n",
      "3         48458                 80          500859   \n",
      "4         47247                443         2969626   \n",
      "\n",
      "   Total Length of Fwd Packets   Fwd Packet Length Max  \\\n",
      "0                         39.0                    39.0   \n",
      "1                          0.0                     0.0   \n",
      "2                        568.0                   517.0   \n",
      "3                        978.0                   978.0   \n",
      "4                         46.0                    23.0   \n",
      "\n",
      "    Bwd Packet Length Mean   Bwd Packet Length Std   Flow IAT Mean  \\\n",
      "0                   103.00                 0.00000    9.531700e+04   \n",
      "1                     0.00                 0.00000    2.584210e+05   \n",
      "2                    37.40                67.64466    1.138498e+06   \n",
      "3                   130.25               260.50000    8.347650e+04   \n",
      "4                     0.00                 0.00000    2.969626e+06   \n",
      "\n",
      "    Flow IAT Max   Flow IAT Min  ...   Init_Win_bytes_backward  \\\n",
      "0        95317.0        95317.0  ...                        -1   \n",
      "1       258421.0       258421.0  ...                       137   \n",
      "2     10094193.0          215.0  ...                        59   \n",
      "3       253401.0           25.0  ...                     65535   \n",
      "4      2969626.0      2969626.0  ...                        -1   \n",
      "\n",
      "    act_data_pkt_fwd  Active Mean   Active Std   Active Max   Active Min  \\\n",
      "0                  0          0.0          0.0          0.0          0.0   \n",
      "1                  0          0.0          0.0          0.0          0.0   \n",
      "2                  2     152071.0          0.0     152071.0     152071.0   \n",
      "3                  1          0.0          0.0          0.0          0.0   \n",
      "4                  1          0.0          0.0          0.0          0.0   \n",
      "\n",
      "    Idle Mean   Idle Std    Idle Max    Idle Min  \n",
      "0         0.0        0.0         0.0         0.0  \n",
      "1         0.0        0.0         0.0         0.0  \n",
      "2  10094193.0        0.0  10094193.0  10094193.0  \n",
      "3         0.0        0.0         0.0         0.0  \n",
      "4         0.0        0.0         0.0         0.0  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# 타깃 변수 열 이름 확인\n",
    "target_variable = ' Label'  # 실제 타깃 변수 열 이름으로 수정\n",
    "\n",
    "# X와 y로 데이터 분할\n",
    "y = sub_dataset[target_variable]  # 타깃 변수\n",
    "X = sub_dataset.drop([target_variable], axis=1)  # 타깃 변수 제외한 나머지 특성\n",
    "\n",
    "# 불필요한 특성 제거 (예시: 'Flow ID', ' Timestamp', ' Source IP', ' Destination IP' 특성 제거)\n",
    "unnecessary_features = ['Flow ID', ' Timestamp', ' Source IP', ' Destination IP']\n",
    "X = X.drop(unnecessary_features, axis=1)\n",
    "\n",
    "# 각 열(feature)에 Min-Max 스케일링 적용\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# chi2를 사용하여 특성 선택 (하위 36개의 특성 선택)\n",
    "num_features_to_select = 36\n",
    "selector = SelectKBest(score_func=chi2, k=num_features_to_select)\n",
    "X_selected = selector.fit_transform(X_scaled, y)\n",
    "\n",
    "# 선택된 특성들의 인덱스 추출\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "\n",
    "# 선택된 특성들의 컬럼명 추출\n",
    "selected_feature_names = X.columns[selected_feature_indices]\n",
    "\n",
    "# 최종 선택된 특성들의 데이터프레임 생성\n",
    "X_final = X[selected_feature_names]\n",
    "\n",
    "# 결과 출력\n",
    "print(\"선택된 특성들의 컬럼명:\")\n",
    "print(selected_feature_names)\n",
    "print(\"\\n최종 선택된 특성들의 데이터프레임:\")\n",
    "print(X_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성들의 순위와 가중치:\n",
      "1. Bwd IAT Total: 54.57963310395508\n",
      "2.  Bwd IAT Max: 55.73380181785601\n",
      "3.  Fwd IAT Std: 55.972731191232015\n",
      "4.  Bwd Packet Length Mean: 63.1108563490311\n",
      "5.  Avg Bwd Segment Size: 63.11085634903111\n",
      "6.  Fwd Packet Length Max: 67.2275268599415\n",
      "7.  Fwd IAT Mean: 68.41141305806283\n",
      "8.  Idle Min: 73.25565940214791\n",
      "9.  Bwd Packet Length Std: 73.39718419578342\n",
      "10. Idle Mean: 73.8250603674548\n",
      "11.  Idle Std: 78.78845887579168\n",
      "12.  Flow IAT Mean: 78.87444216929649\n",
      "13.  Flow IAT Max: 82.33798579259249\n",
      "14.  Fwd IAT Min: 82.58487629530032\n",
      "15.  Idle Max: 82.99597046558867\n",
      "16.  Flow IAT Min: 91.92792382528727\n",
      "17.  Fwd IAT Max: 96.41990946338971\n",
      "18.  Active Min: 99.60030874564774\n",
      "19.  Init_Win_bytes_backward: 119.22358007700582\n",
      "20.  act_data_pkt_fwd: 127.86822541571262\n",
      "21. FIN Flag Count: 152.16124567478806\n",
      "22. Total Length of Fwd Packets: 172.717240631204\n",
      "23.  Subflow Fwd Bytes: 172.717240631204\n",
      "24.  ACK Flag Count: 176.28001974489948\n",
      "25. Active Mean: 205.05607524167073\n",
      "26. Fwd PSH Flags: 223.7051754746605\n",
      "27.  SYN Flag Count: 223.7051754746605\n",
      "28.  Flow Duration: 233.05483395096692\n",
      "29.  Active Max: 382.02744872669155\n",
      "30.  Active Std: 393.8748800478455\n",
      "31. Fwd IAT Total: 472.5559894435117\n",
      "32.  Source Port: 478.4989558578347\n",
      "33.  PSH Flag Count: 608.7286594099377\n",
      "34. Init_Win_bytes_forward: 645.4941831854316\n",
      "35.  URG Flag Count: 991.1392777430855\n",
      "36.  Destination Port: 2887.3174133004654\n"
     ]
    }
   ],
   "source": [
    "# 특성들의 가중치(Chi-square 통계량) 확인\n",
    "chi2_scores = selector.scores_[selected_feature_indices]\n",
    "\n",
    "# 특성들의 가중치를 기준으로 오름차순 정렬\n",
    "sorted_indices = chi2_scores.argsort()\n",
    "sorted_features = selected_feature_names[sorted_indices]\n",
    "sorted_chi2_scores = chi2_scores[sorted_indices]\n",
    "\n",
    "# 특성들의 가중치와 순위 출력\n",
    "print(\"특성들의 순위와 가중치:\")\n",
    "for i, (feature, score) in enumerate(zip(sorted_features, sorted_chi2_scores), 1):\n",
    "    print(f\"{i}. {feature}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_benign_subset의 샘플 개수: 160000\n"
     ]
    }
   ],
   "source": [
    "# 'Benign' 클래스의 파일 경로 리스트 받아오기\n",
    "benign_file_paths = glob.glob(benign_folder_path + '/*.csv')\n",
    "\n",
    "# 'Benign' 클래스의 데이터프레임 초기화\n",
    "benign_data = pd.DataFrame()\n",
    "\n",
    "# 'Benign' 클래스의 모든 파일 로드\n",
    "for file_path in benign_file_paths:\n",
    "    data = pd.read_csv(file_path)\n",
    "    benign_data = pd.concat([benign_data, data], ignore_index=True)\n",
    "\n",
    "# 'Benign' 클래스에서 160,000개 무작위 샘플 추출\n",
    "num_samples_benign = 160000\n",
    "if len(benign_data) > num_samples_benign:\n",
    "    benign_subset = benign_data.sample(n=num_samples_benign, random_state=42)\n",
    "else:\n",
    "    benign_subset = benign_data.copy()\n",
    "\n",
    "print(\"train_benign_subset의 샘플 개수:\", len(benign_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ransomware_subset의 샘플 개수: 40000\n"
     ]
    }
   ],
   "source": [
    "# 각 랜섬웨어 클래스별로 4000개씩 무작위 샘플 추출 (비복원 추출)\n",
    "num_samples_per_ransomware_class = 4000\n",
    "all_ransomware_data = []\n",
    "\n",
    "# Ransomware 폴더 내의 10개 폴더 경로 리스트 받아오기\n",
    "ransomware_folder_list = glob.glob(folder_path + '\\\\Ransomware\\\\*')\n",
    "\n",
    "for ransomware_folder_path in ransomware_folder_list:\n",
    "    ransomware_file_paths = glob.glob(ransomware_folder_path + '/*.csv')\n",
    "    ransomware_data = pd.DataFrame()\n",
    "\n",
    "    # 각 랜섬웨어 클래스의 모든 파일 로드\n",
    "    for file_path in ransomware_file_paths:\n",
    "        data = pd.read_csv(file_path)\n",
    "        ransomware_data = pd.concat([ransomware_data, data], ignore_index=True)\n",
    "\n",
    "    # 랜섬웨어 클래스에서 4000개 무작위 샘플 추출 (비복원 추출)\n",
    "    if len(ransomware_data) > num_samples_per_ransomware_class:\n",
    "        ransomware_subset = ransomware_data.sample(n=num_samples_per_ransomware_class, random_state=42, replace=False)\n",
    "    else:\n",
    "        ransomware_subset = ransomware_data.copy()\n",
    "    all_ransomware_data.append(ransomware_subset)\n",
    "\n",
    "# 모든 랜섬웨어 클래스의 데이터프레임들을 합치기\n",
    "all_ransomware_data_subset = pd.concat(all_ransomware_data, ignore_index=True)\n",
    "\n",
    "print(\"ransomware_subset의 샘플 개수:\", len(all_ransomware_data_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 train 데이터세트의 샘플 개수: 200000\n"
     ]
    }
   ],
   "source": [
    "# 'Benign' 클래스와 랜섬웨어 클래스의 데이터프레임들을 합치기\n",
    "sub_dataset = pd.concat([benign_subset, all_ransomware_data_subset], ignore_index=True)\n",
    "\n",
    "print(\"최종 train 데이터세트의 샘플 개수:\", len(sub_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화된 특성들의 데이터프레임:\n",
      "    Source Port   Destination Port   Flow Duration  \\\n",
      "0      0.592166           0.000811        0.000794   \n",
      "1      0.758065           0.001224        0.002154   \n",
      "2      0.564211           0.006779        0.085388   \n",
      "3      0.739433           0.001224        0.004174   \n",
      "4      0.720954           0.006779        0.024747   \n",
      "\n",
      "   Total Length of Fwd Packets   Fwd Packet Length Max  \\\n",
      "0                     0.000004                0.001924   \n",
      "1                     0.000000                0.000000   \n",
      "2                     0.000058                0.025503   \n",
      "3                     0.000101                0.048244   \n",
      "4                     0.000005                0.001135   \n",
      "\n",
      "    Bwd Packet Length Mean   Bwd Packet Length Std   Flow IAT Mean  \\\n",
      "0                 0.070548                0.000000        0.000795   \n",
      "1                 0.000000                0.000000        0.002155   \n",
      "2                 0.025616                0.062627        0.009495   \n",
      "3                 0.089212                0.241179        0.000696   \n",
      "4                 0.000000                0.000000        0.024767   \n",
      "\n",
      "    Flow IAT Max   Flow IAT Min  ...   Init_Win_bytes_backward  \\\n",
      "0       0.000795   7.950618e-04  ...                  0.000000   \n",
      "1       0.002155   2.155394e-03  ...                  0.002106   \n",
      "2       0.084188   1.884902e-06  ...                  0.000916   \n",
      "3       0.002113   3.002499e-07  ...                  1.000000   \n",
      "4       0.024767   2.476759e-02  ...                  0.000000   \n",
      "\n",
      "    act_data_pkt_fwd  Active Mean   Active Std   Active Max   Active Min  \\\n",
      "0           0.000000     0.000000          0.0     0.000000     0.000000   \n",
      "1           0.000000     0.000000          0.0     0.000000     0.000000   \n",
      "2           0.000297     0.001415          0.0     0.001415     0.001415   \n",
      "3           0.000149     0.000000          0.0     0.000000     0.000000   \n",
      "4           0.000149     0.000000          0.0     0.000000     0.000000   \n",
      "\n",
      "   Idle Mean   Idle Std   Idle Max   Idle Min  \n",
      "0   0.000000        0.0   0.000000   0.000000  \n",
      "1   0.000000        0.0   0.000000   0.000000  \n",
      "2   0.084263        0.0   0.084263   0.084263  \n",
      "3   0.000000        0.0   0.000000   0.000000  \n",
      "4   0.000000        0.0   0.000000   0.000000  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 선택된 36가지 특성에 해당하는 열만 추출\n",
    "selected_feature_columns = X_final.columns\n",
    "selected_feature_values = sub_dataset[selected_feature_columns]\n",
    "\n",
    "# Min-Max 스케일링을 사용하여 선택된 특성들을 0과 1 사이의 값으로 정규화 > normalization으로 쓰기\n",
    "scaler = MinMaxScaler()\n",
    "selected_feature_values_normalized = scaler.fit_transform(selected_feature_values)\n",
    "\n",
    "# 정규화된 특성들을 데이터프레임으로 변환\n",
    "X_final_normalized = pd.DataFrame(selected_feature_values_normalized, columns=selected_feature_columns)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"정규화된 특성들의 데이터프레임:\")\n",
    "print(X_final_normalized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6x6 크기의 2차원 행렬:\n",
      "[[5.92165899e-01 8.11005187e-04 7.94301774e-04 4.00783933e-06\n",
      "  1.92383583e-03 7.05479452e-02]\n",
      " [0.00000000e+00 7.94961759e-04 7.94961759e-04 7.95061763e-04\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 7.05479452e-02]\n",
      " [4.00783933e-06 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# 선택된 36가지 특성을 6x6 크기의 2차원 행렬로 변환\n",
    "num_rows = 6\n",
    "num_columns = 6\n",
    "X_final_reshaped = X_final_normalized.values.reshape(-1, num_rows, num_columns)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"6x6 크기의 2차원 행렬:\")\n",
    "print(X_final_reshaped[0])  # 첫 번째 샘플에 해당하는 6x6 행렬 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 변환 및 저장이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# 이미지를 저장할 폴더를 생성합니다.\n",
    "save_folder = r'C:\\Users\\pc\\Desktop\\CNN\\Train_Image\\\\'\n",
    "os.makedirs(os.path.join(save_folder, \"Benign\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(save_folder, \"Ransomware\"), exist_ok=True)\n",
    "\n",
    "# X_final_reshaped를 이미지로 변환하여 저장합니다.\n",
    "num_samples = X_final_reshaped.shape[0]\n",
    "for i in range(num_samples):\n",
    "    # 1채널 16비트 PNG 이미지 생성\n",
    "    image_data = X_final_reshaped[i]\n",
    "    image_data = (image_data * 65535).astype('uint16')  # 16비트로 변환\n",
    "    image = Image.fromarray(image_data, 'I;16')  # 16비트 단일 채널 이미지로 변환\n",
    "\n",
    "    # 이미지의 라벨에 따라서 저장 위치 및 파일명 설정\n",
    "    if i < 160000:\n",
    "        label = \"Benign\"\n",
    "    else:\n",
    "        label = \"Ransomware\"\n",
    "\n",
    "    image_filename = f\"image_{i}.png\"\n",
    "    image_filepath = os.path.join(save_folder, label, image_filename)\n",
    "\n",
    "    # 해당 경로에 이미지가 이미 존재하는 경우 건너뛴다.\n",
    "    if os.path.exists(image_filepath):\n",
    "        continue\n",
    "\n",
    "    image.save(image_filepath)\n",
    "\n",
    "print(\"이미지 변환 및 저장이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 이미지 데이터를 저장한 폴더 경로\n",
    "image_folder = r'C:\\Users\\pc\\Desktop\\CNN\\Train_Image\\\\'\n",
    "\n",
    "# 이미지 데이터를 불러오고 라벨을 지정합니다.\n",
    "X_data = []\n",
    "y_labels = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    if i < 160000:\n",
    "        label = 0  # Benign 클래스\n",
    "    else:\n",
    "        label = 1  # Ransomware 클래스\n",
    "\n",
    "    image_path = os.path.join(image_folder, f\"image_{i}.png\")\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # 이미지를 그레이스케일로 불러옵니다.\n",
    "    X_data.append(image)\n",
    "    y_labels.append(label)\n",
    "\n",
    "X_data = np.array(X_data)\n",
    "y_labels = np.array(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Benign samples: 160000\n",
      "Number of Ransomware samples: 40000\n"
     ]
    }
   ],
   "source": [
    "# Count the number of samples in each class\n",
    "num_benign_samples = np.count_nonzero(y_labels == 0)\n",
    "num_ransomware_samples = np.count_nonzero(y_labels == 1)\n",
    "\n",
    "print(\"Number of Benign samples:\", num_benign_samples)\n",
    "print(\"Number of Ransomware samples:\", num_ransomware_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존에 train 데이터셋으로 사용된 인덱스를 추출\n",
    "train_benign_indices = benign_subset.index\n",
    "train_ransomware_indices = all_ransomware_data_subset.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation_benign_subset의 샘플 개수: 20000\n"
     ]
    }
   ],
   "source": [
    "# 사용되지 않은 benign 데이터에서 추가로 20,000개 추출\n",
    "remaining_benign_data = benign_data.drop(train_benign_indices)\n",
    "num_samples_val_benign = 20000\n",
    "if len(remaining_benign_data) > num_samples_val_benign:\n",
    "    val_benign_subset = remaining_benign_data.sample(n=num_samples_val_benign, random_state=42)\n",
    "else:\n",
    "    val_benign_subset = remaining_benign_data.copy()\n",
    "\n",
    "print(\"Validation_benign_subset의 샘플 개수:\", len(val_benign_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation_ransomware_subset의 샘플 개수: 1200\n"
     ]
    }
   ],
   "source": [
    "num_samples_additional = 400\n",
    "val_ransomware_subset = []\n",
    "\n",
    "for ransomware_folder_path in ransomware_folder_list:\n",
    "    ransomware_file_paths = glob.glob(ransomware_folder_path + '/*.csv')\n",
    "    ransomware_data = pd.DataFrame()\n",
    "\n",
    "    # 각 랜섬웨어 클래스의 모든 파일 로드\n",
    "    for file_path in ransomware_file_paths:\n",
    "        data = pd.read_csv(file_path)\n",
    "        ransomware_data = pd.concat([ransomware_data, data], ignore_index=True)\n",
    "\n",
    "    # 이미 선택된 샘플들 제외\n",
    "    remaining_data = ransomware_data.drop(train_ransomware_indices, errors='ignore')\n",
    "\n",
    "    # 400개의 샘플 추출\n",
    "    if len(remaining_data) > num_samples_additional:\n",
    "        subset = remaining_data.sample(n=num_samples_additional, random_state=42)\n",
    "    else:\n",
    "        subset = remaining_data.copy()\n",
    "    \n",
    "    val_ransomware_subset.append(subset)\n",
    "\n",
    "# 모든 추가된 랜섬웨어 데이터의 데이터프레임들을 합치기\n",
    "val_ransomware_subset = pd.concat(val_ransomware_subset, ignore_index=True)\n",
    "\n",
    "print(\"Validation_ransomware_subset의 샘플 개수:\", len(val_ransomware_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Validation 데이터세트의 샘플 개수: 21200\n"
     ]
    }
   ],
   "source": [
    "# 'Benign' 클래스와 랜섬웨어 클래스의 데이터프레임들을 합치기\n",
    "val_sub_dataset = pd.concat([val_benign_subset, val_ransomware_subset], ignore_index=True)\n",
    "\n",
    "print(\"최종 Validation 데이터세트의 샘플 개수:\", len(val_sub_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Validation 데이터세트의 샘플 개수: 21200\n"
     ]
    }
   ],
   "source": [
    "# 'Benign' 클래스와 랜섬웨어 클래스의 데이터프레임들을 합치기\n",
    "val_sub_dataset = pd.concat([val_benign_subset, val_ransomware_subset], ignore_index=True)\n",
    "\n",
    "print(\"최종 Validation 데이터세트의 샘플 개수:\", len(val_sub_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택된 36가지 특성에 해당하는 열만 추출 (Validation 데이터셋)\n",
    "val_selected_feature_values = val_sub_dataset[selected_feature_columns]\n",
    "\n",
    "# Min-Max 스케일링을 사용하여 선택된 특성들을 0과 1 사이의 값으로 정규화 (Validation 데이터셋)\n",
    "val_selected_feature_values_normalized = scaler.transform(val_selected_feature_values)\n",
    "\n",
    "# 정규화된 특성들을 데이터프레임으로 변환 (Validation 데이터셋)\n",
    "X_val_normalized = pd.DataFrame(val_selected_feature_values_normalized, columns=selected_feature_columns)\n",
    "\n",
    "# 선택된 36가지 특성을 6x6 크기의 2차원 행렬로 변환 (Validation 데이터셋)\n",
    "X_val_reshaped = X_val_normalized.values.reshape(-1, num_rows, num_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation 이미지 변환 및 저장이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 이미지를 저장할 폴더를 생성합니다.\n",
    "val_save_folder = r'C:\\Users\\pc\\Desktop\\CNN\\Validation_Image\\\\'\n",
    "os.makedirs(os.path.join(val_save_folder, \"Benign\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(val_save_folder, \"Ransomware\"), exist_ok=True)\n",
    "\n",
    "# X_val_reshaped를 이미지로 변환하여 저장합니다.\n",
    "num_val_samples = X_val_reshaped.shape[0]\n",
    "for i in range(num_val_samples):\n",
    "    # 1채널 16비트 PNG 이미지 생성\n",
    "    image_data = X_val_reshaped[i]\n",
    "    image_data = (image_data * 65535).astype('uint16')  # 16비트로 변환\n",
    "    image = Image.fromarray(image_data, 'I;16')  # 16비트 단일 채널 이미지로 변환\n",
    "\n",
    "    # 이미지의 라벨에 따라서 저장 위치 및 파일명 설정\n",
    "    if i < num_samples_val_benign:\n",
    "        label = \"Benign\"\n",
    "    else:\n",
    "        label = \"Ransomware\"\n",
    "\n",
    "    image_filename = f\"image_{i}.png\"\n",
    "    image.save(os.path.join(val_save_folder, label, image_filename))\n",
    "\n",
    "print(\"Validation 이미지 변환 및 저장이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_benign_subset의 샘플 개수: 20000\n"
     ]
    }
   ],
   "source": [
    "benign_folder_path = r'C:\\Users\\pc\\Desktop\\CNN\\CIC-AndMal2017\\Benign'\n",
    "\n",
    "# 'Benign' 클래스의 파일 경로 리스트 받아오기\n",
    "test_benign_file_paths = glob.glob(benign_folder_path + '/*.csv')\n",
    "\n",
    "# 'Benign' 클래스의 데이터프레임 초기화\n",
    "test_benign_data = pd.DataFrame()\n",
    "\n",
    "# 'Benign' 클래스의 모든 파일 로드\n",
    "for file_path in test_benign_file_paths:\n",
    "    data = pd.read_csv(file_path)\n",
    "    test_benign_data = pd.concat([test_benign_data, data], ignore_index=True)\n",
    "\n",
    "# 'Benign' 클래스에서 20,000개 무작위 샘플 추출 (Test 데이터셋)\n",
    "num_samples_test_benign = 20000\n",
    "if len(test_benign_data) > num_samples_test_benign:\n",
    "    test_benign_subset = test_benign_data.sample(n=num_samples_test_benign, random_state=42)\n",
    "else:\n",
    "    test_benign_subset = test_benign_data.copy()\n",
    "\n",
    "print(\"test_benign_subset의 샘플 개수:\", len(test_benign_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ransomware_subset의 샘플 개수: 4000\n"
     ]
    }
   ],
   "source": [
    "# 각 랜섬웨어 클래스별로 400개씩 무작위 샘플 추출 (비복원 추출)\n",
    "num_samples_per_ransomware_class = 400\n",
    "all_ransomware_data = []\n",
    "\n",
    "# Ransomware 폴더 내의 10개 폴더 경로 리스트 받아오기\n",
    "ransomware_folder_list = glob.glob(folder_path + '\\\\Ransomware\\\\*')\n",
    "\n",
    "for ransomware_folder_path in ransomware_folder_list:\n",
    "    ransomware_file_paths = glob.glob(ransomware_folder_path + '/*.csv')\n",
    "    ransomware_data = pd.DataFrame()\n",
    "\n",
    "    # 각 랜섬웨어 클래스의 모든 파일 로드\n",
    "    for file_path in ransomware_file_paths:\n",
    "        data = pd.read_csv(file_path)\n",
    "        ransomware_data = pd.concat([ransomware_data, data], ignore_index=True)\n",
    "\n",
    "    # 랜섬웨어 클래스에서 400개 무작위 샘플 추출 (비복원 추출)\n",
    "    if len(ransomware_data) > num_samples_per_ransomware_class:\n",
    "        ransomware_subset = ransomware_data.sample(n=num_samples_per_ransomware_class, random_state=42, replace=False)\n",
    "    else:\n",
    "        ransomware_subset = ransomware_data.copy()\n",
    "    all_ransomware_data.append(ransomware_subset)\n",
    "\n",
    "# 모든 랜섬웨어 클래스의 데이터프레임들을 합치기\n",
    "all_test_ransomware_data_subset = pd.concat(all_ransomware_data, ignore_index=True)\n",
    "\n",
    "print(\"ransomware_subset의 샘플 개수:\", len(all_test_ransomware_data_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Test 서브 데이터세트의 샘플 개수: 24000\n"
     ]
    }
   ],
   "source": [
    "# 'Benign' 클래스와 랜섬웨어 클래스의 데이터프레임들을 합치기 (Test 데이터셋)\n",
    "test_sub_dataset = pd.concat([test_benign_subset, all_test_ransomware_data_subset], ignore_index=True)\n",
    "\n",
    "print(\"최종 Test 서브 데이터세트의 샘플 개수:\", len(test_sub_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택된 36가지 특성에 해당하는 열만 추출 (Test 데이터셋)\n",
    "test_selected_feature_values = test_sub_dataset[selected_feature_columns]\n",
    "\n",
    "# Min-Max 스케일링을 사용하여 선택된 특성들을 0과 1 사이의 값으로 정규화 (Test 데이터셋)\n",
    "test_selected_feature_values_normalized = scaler.transform(test_selected_feature_values)\n",
    "\n",
    "# 정규화된 특성들을 데이터프레임으로 변환 (Test 데이터셋)\n",
    "X_test_normalized = pd.DataFrame(test_selected_feature_values_normalized, columns=selected_feature_columns)\n",
    "\n",
    "# 선택된 36가지 특성을 6x6 크기의 2차원 행렬로 변환 (Test 데이터셋)\n",
    "X_test_reshaped = X_test_normalized.values.reshape(-1, num_rows, num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 이미지 변환 및 저장이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 이미지를 저장할 폴더를 생성합니다.\n",
    "test_save_folder = r'C:\\Users\\pc\\Desktop\\CNN\\Test_Image\\\\'\n",
    "os.makedirs(os.path.join(test_save_folder, \"Benign\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(test_save_folder, \"Ransomware\"), exist_ok=True)\n",
    "\n",
    "# X_test_reshaped를 이미지로 변환하여 저장합니다.\n",
    "num_test_samples = X_test_reshaped.shape[0]\n",
    "for i in range(num_test_samples):\n",
    "    # 이미지의 라벨에 따라서 저장 위치 및 파일명 설정\n",
    "    if i < num_samples_test_benign:\n",
    "        label = \"Benign\"\n",
    "    else:\n",
    "        label = \"Ransomware\"\n",
    "\n",
    "    image_filename = f\"image_{i}.png\"\n",
    "    image_path = os.path.join(test_save_folder, label, image_filename)\n",
    "    \n",
    "    # 이미 해당 경로에 이미지가 있다면, 저장하지 않고 넘어갑니다.\n",
    "    if os.path.exists(image_path):\n",
    "        continue\n",
    "\n",
    "    # 1채널 16비트 PNG 이미지 생성\n",
    "    image_data = X_test_reshaped[i]\n",
    "    image_data = (image_data * 65535).astype('uint16')  # 16비트로 변환\n",
    "    image = Image.fromarray(image_data, 'I;16')  # 16비트 단일 채널 이미지로 변환\n",
    "    \n",
    "    image.save(image_path)\n",
    "    \n",
    "print(\"Test 이미지 변환 및 저장이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Convolution 1\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Maxpooling 1\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Convolution 2\n",
    "    model.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Maxpooling 2\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Convolution 3\n",
    "    model.add(layers.Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Maxpooling 3\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Flatten\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # FC 1\n",
    "    model.add(layers.Dense(2048, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    # FC 2\n",
    "    model.add(layers.Dense(2048, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    # FC 3 (출력층)\n",
    "    model.add(layers.Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200000 images belonging to 2 classes.\n",
      "Found 24000 images belonging to 2 classes.\n",
      "Found 24000 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "6250/6250 [==============================] - 727s 115ms/step - loss: 0.5095 - accuracy: 0.7992 - auc: 0.5275 - val_loss: 0.4508 - val_accuracy: 0.8333 - val_auc: 0.5551\n",
      "Epoch 2/50\n",
      "6250/6250 [==============================] - 476s 76ms/step - loss: 0.4979 - accuracy: 0.8003 - auc: 0.5560 - val_loss: 0.4499 - val_accuracy: 0.8342 - val_auc: 0.5918\n",
      "Epoch 3/50\n",
      "6250/6250 [==============================] - 459s 73ms/step - loss: 0.4896 - accuracy: 0.8009 - auc: 0.5941 - val_loss: 0.4358 - val_accuracy: 0.8360 - val_auc: 0.6282\n",
      "Epoch 4/50\n",
      "6250/6250 [==============================] - 415s 66ms/step - loss: 0.4861 - accuracy: 0.8013 - auc: 0.6068 - val_loss: 0.4429 - val_accuracy: 0.8353 - val_auc: 0.6450\n",
      "Epoch 5/50\n",
      "6250/6250 [==============================] - 457s 73ms/step - loss: 0.4813 - accuracy: 0.8030 - auc: 0.6192 - val_loss: 0.4310 - val_accuracy: 0.8413 - val_auc: 0.6449\n",
      "Epoch 6/50\n",
      "6250/6250 [==============================] - 456s 73ms/step - loss: 0.4775 - accuracy: 0.8042 - auc: 0.6279 - val_loss: 0.4345 - val_accuracy: 0.8403 - val_auc: 0.6356\n",
      "Epoch 7/50\n",
      "6250/6250 [==============================] - 418s 67ms/step - loss: 0.4758 - accuracy: 0.8049 - auc: 0.6339 - val_loss: 0.4206 - val_accuracy: 0.8419 - val_auc: 0.6612\n",
      "Epoch 8/50\n",
      "6250/6250 [==============================] - 417s 67ms/step - loss: 0.4737 - accuracy: 0.8054 - auc: 0.6385 - val_loss: 0.4205 - val_accuracy: 0.8411 - val_auc: 0.6524\n",
      "Epoch 9/50\n",
      "6250/6250 [==============================] - 348s 56ms/step - loss: 0.4726 - accuracy: 0.8058 - auc: 0.6417 - val_loss: 0.4295 - val_accuracy: 0.8407 - val_auc: 0.6563\n",
      "Epoch 10/50\n",
      "6250/6250 [==============================] - 251s 40ms/step - loss: 0.4719 - accuracy: 0.8063 - auc: 0.6442 - val_loss: 0.4268 - val_accuracy: 0.8414 - val_auc: 0.6645\n",
      "Epoch 11/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4700 - accuracy: 0.8067 - auc: 0.6487 - val_loss: 0.4200 - val_accuracy: 0.8429 - val_auc: 0.6702\n",
      "Epoch 12/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4686 - accuracy: 0.8068 - auc: 0.6531 - val_loss: 0.4126 - val_accuracy: 0.8427 - val_auc: 0.6748\n",
      "Epoch 13/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4670 - accuracy: 0.8072 - auc: 0.6571 - val_loss: 0.4129 - val_accuracy: 0.8426 - val_auc: 0.6789\n",
      "Epoch 14/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4656 - accuracy: 0.8077 - auc: 0.6598 - val_loss: 0.4137 - val_accuracy: 0.8434 - val_auc: 0.6812\n",
      "Epoch 15/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4651 - accuracy: 0.8079 - auc: 0.6613 - val_loss: 0.4162 - val_accuracy: 0.8412 - val_auc: 0.6896\n",
      "Epoch 16/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4657 - accuracy: 0.8076 - auc: 0.6616 - val_loss: 0.4112 - val_accuracy: 0.8430 - val_auc: 0.6881\n",
      "Epoch 17/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4656 - accuracy: 0.8074 - auc: 0.6617 - val_loss: 0.4212 - val_accuracy: 0.8430 - val_auc: 0.6635\n",
      "Epoch 18/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4636 - accuracy: 0.8079 - auc: 0.6657 - val_loss: 0.4138 - val_accuracy: 0.8431 - val_auc: 0.6894\n",
      "Epoch 19/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4621 - accuracy: 0.8080 - auc: 0.6689 - val_loss: 0.4133 - val_accuracy: 0.8423 - val_auc: 0.6869\n",
      "Epoch 20/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4620 - accuracy: 0.8080 - auc: 0.6712 - val_loss: 0.4104 - val_accuracy: 0.8445 - val_auc: 0.6950\n",
      "Epoch 21/50\n",
      "6250/6250 [==============================] - 251s 40ms/step - loss: 0.4606 - accuracy: 0.8085 - auc: 0.6750 - val_loss: 0.4130 - val_accuracy: 0.8416 - val_auc: 0.7070\n",
      "Epoch 22/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4596 - accuracy: 0.8086 - auc: 0.6761 - val_loss: 0.4086 - val_accuracy: 0.8445 - val_auc: 0.7014\n",
      "Epoch 23/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4588 - accuracy: 0.8086 - auc: 0.6803 - val_loss: 0.4131 - val_accuracy: 0.8406 - val_auc: 0.6987\n",
      "Epoch 24/50\n",
      "6250/6250 [==============================] - 251s 40ms/step - loss: 0.4571 - accuracy: 0.8086 - auc: 0.6838 - val_loss: 0.4097 - val_accuracy: 0.8420 - val_auc: 0.7030\n",
      "Epoch 25/50\n",
      "6250/6250 [==============================] - 249s 40ms/step - loss: 0.4565 - accuracy: 0.8085 - auc: 0.6852 - val_loss: 0.4195 - val_accuracy: 0.8415 - val_auc: 0.6906\n",
      "Epoch 26/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4562 - accuracy: 0.8089 - auc: 0.6852 - val_loss: 0.4060 - val_accuracy: 0.8429 - val_auc: 0.7064\n",
      "Epoch 27/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4553 - accuracy: 0.8089 - auc: 0.6873 - val_loss: 0.4105 - val_accuracy: 0.8418 - val_auc: 0.7059\n",
      "Epoch 28/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4579 - accuracy: 0.8083 - auc: 0.6843 - val_loss: 0.4069 - val_accuracy: 0.8432 - val_auc: 0.7148\n",
      "Epoch 29/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4556 - accuracy: 0.8085 - auc: 0.6877 - val_loss: 0.4113 - val_accuracy: 0.8419 - val_auc: 0.7010\n",
      "Epoch 30/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4554 - accuracy: 0.8087 - auc: 0.6889 - val_loss: 0.4079 - val_accuracy: 0.8421 - val_auc: 0.7124\n",
      "Epoch 31/50\n",
      "6250/6250 [==============================] - 251s 40ms/step - loss: 0.4543 - accuracy: 0.8092 - auc: 0.6889 - val_loss: 0.4068 - val_accuracy: 0.8421 - val_auc: 0.7131\n",
      "Epoch 32/50\n",
      "6250/6250 [==============================] - 251s 40ms/step - loss: 0.4527 - accuracy: 0.8094 - auc: 0.6932 - val_loss: 0.4114 - val_accuracy: 0.8400 - val_auc: 0.7053\n",
      "Epoch 33/50\n",
      "6250/6250 [==============================] - 251s 40ms/step - loss: 0.4525 - accuracy: 0.8095 - auc: 0.6935 - val_loss: 0.4091 - val_accuracy: 0.8430 - val_auc: 0.7157\n",
      "Epoch 34/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4515 - accuracy: 0.8101 - auc: 0.6958 - val_loss: 0.4054 - val_accuracy: 0.8440 - val_auc: 0.7181\n",
      "Epoch 35/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4519 - accuracy: 0.8099 - auc: 0.6954 - val_loss: 0.4076 - val_accuracy: 0.8419 - val_auc: 0.7136\n",
      "Epoch 36/50\n",
      "6250/6250 [==============================] - 251s 40ms/step - loss: 0.4514 - accuracy: 0.8101 - auc: 0.6974 - val_loss: 0.4062 - val_accuracy: 0.8431 - val_auc: 0.7171\n",
      "Epoch 37/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4508 - accuracy: 0.8102 - auc: 0.6982 - val_loss: 0.4047 - val_accuracy: 0.8419 - val_auc: 0.7171\n",
      "Epoch 38/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4505 - accuracy: 0.8102 - auc: 0.6971 - val_loss: 0.4080 - val_accuracy: 0.8436 - val_auc: 0.7128\n",
      "Epoch 39/50\n",
      "6250/6250 [==============================] - 251s 40ms/step - loss: 0.4500 - accuracy: 0.8101 - auc: 0.6995 - val_loss: 0.4128 - val_accuracy: 0.8425 - val_auc: 0.7090\n",
      "Epoch 40/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4498 - accuracy: 0.8099 - auc: 0.7005 - val_loss: 0.4012 - val_accuracy: 0.8433 - val_auc: 0.7126\n",
      "Epoch 41/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4486 - accuracy: 0.8105 - auc: 0.7015 - val_loss: 0.4097 - val_accuracy: 0.8415 - val_auc: 0.7232\n",
      "Epoch 42/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4490 - accuracy: 0.8101 - auc: 0.7018 - val_loss: 0.4073 - val_accuracy: 0.8428 - val_auc: 0.7203\n",
      "Epoch 43/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4494 - accuracy: 0.8107 - auc: 0.7004 - val_loss: 0.4066 - val_accuracy: 0.8423 - val_auc: 0.7205\n",
      "Epoch 44/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4482 - accuracy: 0.8112 - auc: 0.7024 - val_loss: 0.4019 - val_accuracy: 0.8422 - val_auc: 0.7202\n",
      "Epoch 45/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4469 - accuracy: 0.8111 - auc: 0.7047 - val_loss: 0.4051 - val_accuracy: 0.8403 - val_auc: 0.7271\n",
      "Epoch 46/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4477 - accuracy: 0.8110 - auc: 0.7028 - val_loss: 0.4138 - val_accuracy: 0.8425 - val_auc: 0.7047\n",
      "Epoch 47/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4489 - accuracy: 0.8110 - auc: 0.7015 - val_loss: 0.4097 - val_accuracy: 0.8385 - val_auc: 0.7155\n",
      "Epoch 48/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4485 - accuracy: 0.8110 - auc: 0.7032 - val_loss: 0.4085 - val_accuracy: 0.8425 - val_auc: 0.7187\n",
      "Epoch 49/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4472 - accuracy: 0.8111 - auc: 0.7044 - val_loss: 0.4048 - val_accuracy: 0.8419 - val_auc: 0.7230\n",
      "Epoch 50/50\n",
      "6250/6250 [==============================] - 250s 40ms/step - loss: 0.4472 - accuracy: 0.8115 - auc: 0.7044 - val_loss: 0.4104 - val_accuracy: 0.8412 - val_auc: 0.7176\n",
      "750/750 [==============================] - 28s 37ms/step - loss: 0.4070 - accuracy: 0.8423 - auc: 0.7111\n",
      "Test Loss: 0.4069780707359314\n",
      "Test Accuracy: 0.8422916531562805\n",
      "Test AUC: 0.7111145257949829\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 이미지 데이터 폴더 경로\n",
    "train_data_folder = r'C:\\Users\\pc\\Desktop\\CNN\\Train_Image'\n",
    "val_data_folder = r'C:\\Users\\pc\\Desktop\\CNN\\Validation_Image'\n",
    "test_data_folder = r'C:\\Users\\pc\\Desktop\\CNN\\Test_Image'\n",
    "\n",
    "# 모델 생성\n",
    "input_shape = (28, 28, 1)  # 입력 이미지의 크기와 채널 수\n",
    "num_classes = 1  # 이진 분류 문제의 경우 클래스 개수는 1\n",
    "model = create_model(input_shape, num_classes)\n",
    "\n",
    "# ImageDataGenerator 생성\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 학습 데이터 로드\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_data_folder,\n",
    "    target_size=(28, 28),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Validation 데이터 로드\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    val_data_folder,\n",
    "    target_size=(28, 28),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=False  # Validation 데이터는 섞지 않음\n",
    ")\n",
    "\n",
    "# Test 데이터 로드\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_data_folder,\n",
    "    target_size=(28, 28),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=False  # Test 데이터는 섞지 않음\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "epochs = 50\n",
    "history = model.fit(train_generator, epochs=epochs, validation_data=val_generator)\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_accuracy, test_auc = model.evaluate(test_generator)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test AUC:\", test_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
