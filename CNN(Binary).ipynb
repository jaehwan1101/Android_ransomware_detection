{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 폴더 경로 지정\n",
    "folder_path = r'C:\\Users\\pc\\Desktop\\CNN\\CIC-AndMal2017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charger 클래스의 샘플 개수: 39551\n",
      "Jisut 클래스의 샘플 개수: 25672\n",
      "Koler 클래스의 샘플 개수: 44555\n",
      "Lockerpin 클래스의 샘플 개수: 25307\n",
      "Pletor 클래스의 샘플 개수: 4715\n",
      "PornDroid 클래스의 샘플 개수: 46082\n",
      "RansomBO 클래스의 샘플 개수: 39859\n",
      "Simplocker 클래스의 샘플 개수: 36340\n",
      "SVpeng 클래스의 샘플 개수: 54161\n",
      "WannaLocker 클래스의 샘플 개수: 32701\n"
     ]
    }
   ],
   "source": [
    "# 랜섬웨어 클래스별 파일에 있는 샘플 개수를 확인하기 위한 딕셔너리\n",
    "samples_per_class = {}\n",
    "\n",
    "# Ransomware 폴더 내의 10개 폴더 경로 리스트 받아오기\n",
    "ransomware_folder_list = glob.glob(folder_path + '\\\\Ransomware\\\\*')\n",
    "\n",
    "# 모든 파일 로드 및 샘플 개수 확인\n",
    "for folder in ransomware_folder_list:\n",
    "    ransomware_class = folder.split('\\\\')[-1]  # 랜섬웨어 클래스명 추출\n",
    "\n",
    "    file_paths = glob.glob(folder + '\\\\*.csv')\n",
    "    total_samples = 0  # 클래스별 전체 샘플 개수 초기화\n",
    "    for file_path in file_paths:\n",
    "        data = pd.read_csv(file_path)\n",
    "        total_samples += data.shape[0]  # 데이터프레임의 행 수 / 샘플 개수 더하기\n",
    "\n",
    "    samples_per_class[ransomware_class] = total_samples\n",
    "\n",
    "# 클래스별 샘플 개수 출력\n",
    "for ransomware_class, num_samples in samples_per_class.items():\n",
    "    print(f\"{ransomware_class} 클래스의 샘플 개수: {num_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign_subset의 샘플 개수: 45000\n"
     ]
    }
   ],
   "source": [
    "benign_folder_path = r'C:\\Users\\pc\\Desktop\\CNN\\CIC-AndMal2017\\Benign'\n",
    "\n",
    "# 'Benign' 클래스의 파일 경로 리스트 받아오기\n",
    "benign_file_paths = glob.glob(benign_folder_path + '/*.csv')\n",
    "\n",
    "# 'Benign' 클래스의 데이터프레임 초기화\n",
    "benign_data = pd.DataFrame()\n",
    "\n",
    "# 'Benign' 클래스의 모든 파일 로드\n",
    "for file_path in benign_file_paths:\n",
    "    data = pd.read_csv(file_path)\n",
    "    benign_data = pd.concat([benign_data, data], ignore_index=True)\n",
    "\n",
    "# 'Benign' 클래스에서 45,000개 무작위 샘플 추출\n",
    "num_samples_benign = 45000\n",
    "if len(benign_data) > num_samples_benign:\n",
    "    benign_subset = benign_data.sample(n=num_samples_benign, random_state=42)\n",
    "else:\n",
    "    benign_subset = benign_data.copy()\n",
    "\n",
    "print(\"benign_subset의 샘플 개수:\", len(benign_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ransomware_subset의 샘플 개수: 45000\n"
     ]
    }
   ],
   "source": [
    "# 각 랜섬웨어 클래스별로 4,500개씩 무작위 샘플 추출 (비복원 추출)\n",
    "num_samples_per_ransomware_class = 4500\n",
    "all_ransomware_data = []\n",
    "\n",
    "# Ransomware 폴더 내의 10개 폴더 경로 리스트 받아오기\n",
    "ransomware_folder_list = glob.glob(folder_path + '\\\\Ransomware\\\\*')\n",
    "\n",
    "for ransomware_folder_path in ransomware_folder_list:\n",
    "    ransomware_file_paths = glob.glob(ransomware_folder_path + '/*.csv')\n",
    "    ransomware_data = pd.DataFrame()\n",
    "\n",
    "    # 각 랜섬웨어 클래스의 모든 파일 로드\n",
    "    for file_path in ransomware_file_paths:\n",
    "        data = pd.read_csv(file_path)\n",
    "        ransomware_data = pd.concat([ransomware_data, data], ignore_index=True)\n",
    "\n",
    "    # 랜섬웨어 클래스에서 4,500개 무작위 샘플 추출 (비복원 추출)\n",
    "    if len(ransomware_data) > num_samples_per_ransomware_class:\n",
    "        ransomware_subset = ransomware_data.sample(n=num_samples_per_ransomware_class, random_state=42, replace=False)\n",
    "    else:\n",
    "        ransomware_subset = ransomware_data.copy()\n",
    "    all_ransomware_data.append(ransomware_subset)\n",
    "\n",
    "# 모든 랜섬웨어 클래스의 데이터프레임들을 합치기\n",
    "all_ransomware_data = pd.concat(all_ransomware_data, ignore_index=True)\n",
    "\n",
    "print(\"ransomware_subset의 샘플 개수:\", len(all_ransomware_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 특성추출 데이터세트의 샘플 개수: 90000\n"
     ]
    }
   ],
   "source": [
    "# 'Benign' 클래스와 랜섬웨어 클래스의 데이터프레임들을 합치기\n",
    "sub_dataset = pd.concat([benign_subset, all_ransomware_data], ignore_index=True)\n",
    "\n",
    "print(\"최종 특성추출 데이터세트의 샘플 개수:\", len(sub_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선택된 특성들의 컬럼명:\n",
      "Index([' Source Port', ' Destination Port', ' Flow Duration',\n",
      "       'Total Length of Fwd Packets', ' Fwd Packet Length Max',\n",
      "       ' Bwd Packet Length Mean', ' Bwd Packet Length Std', ' Flow IAT Mean',\n",
      "       ' Flow IAT Max', ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean',\n",
      "       ' Fwd IAT Std', ' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Total',\n",
      "       ' Bwd IAT Max', 'Fwd PSH Flags', 'FIN Flag Count', ' SYN Flag Count',\n",
      "       ' PSH Flag Count', ' ACK Flag Count', ' URG Flag Count',\n",
      "       ' Avg Bwd Segment Size', ' Subflow Fwd Bytes', 'Init_Win_bytes_forward',\n",
      "       ' Init_Win_bytes_backward', ' act_data_pkt_fwd', 'Active Mean',\n",
      "       ' Active Std', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std',\n",
      "       ' Idle Max', ' Idle Min'],\n",
      "      dtype='object')\n",
      "\n",
      "최종 선택된 특성들의 데이터프레임:\n",
      "    Source Port   Destination Port   Flow Duration  \\\n",
      "0         38807                 53           95317   \n",
      "1         49679                 80          258421   \n",
      "2         36975                443        10246479   \n",
      "3         48458                 80          500859   \n",
      "4         47247                443         2969626   \n",
      "\n",
      "   Total Length of Fwd Packets   Fwd Packet Length Max  \\\n",
      "0                         39.0                    39.0   \n",
      "1                          0.0                     0.0   \n",
      "2                        568.0                   517.0   \n",
      "3                        978.0                   978.0   \n",
      "4                         46.0                    23.0   \n",
      "\n",
      "    Bwd Packet Length Mean   Bwd Packet Length Std   Flow IAT Mean  \\\n",
      "0                   103.00                 0.00000    9.531700e+04   \n",
      "1                     0.00                 0.00000    2.584210e+05   \n",
      "2                    37.40                67.64466    1.138498e+06   \n",
      "3                   130.25               260.50000    8.347650e+04   \n",
      "4                     0.00                 0.00000    2.969626e+06   \n",
      "\n",
      "    Flow IAT Max   Flow IAT Min  ...   Init_Win_bytes_backward  \\\n",
      "0        95317.0        95317.0  ...                        -1   \n",
      "1       258421.0       258421.0  ...                       137   \n",
      "2     10094193.0          215.0  ...                        59   \n",
      "3       253401.0           25.0  ...                     65535   \n",
      "4      2969626.0      2969626.0  ...                        -1   \n",
      "\n",
      "    act_data_pkt_fwd  Active Mean   Active Std   Active Max   Active Min  \\\n",
      "0                  0          0.0          0.0          0.0          0.0   \n",
      "1                  0          0.0          0.0          0.0          0.0   \n",
      "2                  2     152071.0          0.0     152071.0     152071.0   \n",
      "3                  1          0.0          0.0          0.0          0.0   \n",
      "4                  1          0.0          0.0          0.0          0.0   \n",
      "\n",
      "    Idle Mean   Idle Std    Idle Max    Idle Min  \n",
      "0         0.0        0.0         0.0         0.0  \n",
      "1         0.0        0.0         0.0         0.0  \n",
      "2  10094193.0        0.0  10094193.0  10094193.0  \n",
      "3         0.0        0.0         0.0         0.0  \n",
      "4         0.0        0.0         0.0         0.0  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# 타깃 변수 열 이름 확인\n",
    "target_variable = ' Label'  # 실제 타깃 변수 열 이름으로 수정\n",
    "\n",
    "# X와 y로 데이터 분할\n",
    "y = sub_dataset[target_variable]  # 타깃 변수\n",
    "X = sub_dataset.drop([target_variable], axis=1)  # 타깃 변수 제외한 나머지 특성\n",
    "\n",
    "# 불필요한 특성 제거 (예시: 'Flow ID', ' Timestamp', ' Source IP', ' Destination IP' 특성 제거)\n",
    "unnecessary_features = ['Flow ID', ' Timestamp', ' Source IP', ' Destination IP']\n",
    "X = X.drop(unnecessary_features, axis=1)\n",
    "\n",
    "# 각 열(feature)에 Min-Max 스케일링 적용\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# chi2를 사용하여 특성 선택 (하위 36개의 특성 선택)\n",
    "num_features_to_select = 36\n",
    "selector = SelectKBest(score_func=chi2, k=num_features_to_select)\n",
    "X_selected = selector.fit_transform(X_scaled, y)\n",
    "\n",
    "# 선택된 특성들의 인덱스 추출\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "\n",
    "# 선택된 특성들의 컬럼명 추출\n",
    "selected_feature_names = X.columns[selected_feature_indices]\n",
    "\n",
    "# 최종 선택된 특성들의 데이터프레임 생성\n",
    "X_final = X[selected_feature_names]\n",
    "\n",
    "# 결과 출력\n",
    "print(\"선택된 특성들의 컬럼명:\")\n",
    "print(selected_feature_names)\n",
    "print(\"\\n최종 선택된 특성들의 데이터프레임:\")\n",
    "print(X_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성들의 순위와 가중치:\n",
      "1. Bwd IAT Total: 54.57963310395508\n",
      "2.  Bwd IAT Max: 55.73380181785601\n",
      "3.  Fwd IAT Std: 55.972731191232015\n",
      "4.  Bwd Packet Length Mean: 63.1108563490311\n",
      "5.  Avg Bwd Segment Size: 63.11085634903111\n",
      "6.  Fwd Packet Length Max: 67.2275268599415\n",
      "7.  Fwd IAT Mean: 68.41141305806283\n",
      "8.  Idle Min: 73.25565940214791\n",
      "9.  Bwd Packet Length Std: 73.39718419578342\n",
      "10. Idle Mean: 73.8250603674548\n",
      "11.  Idle Std: 78.78845887579168\n",
      "12.  Flow IAT Mean: 78.87444216929649\n",
      "13.  Flow IAT Max: 82.33798579259249\n",
      "14.  Fwd IAT Min: 82.58487629530032\n",
      "15.  Idle Max: 82.99597046558867\n",
      "16.  Flow IAT Min: 91.92792382528727\n",
      "17.  Fwd IAT Max: 96.41990946338971\n",
      "18.  Active Min: 99.60030874564774\n",
      "19.  Init_Win_bytes_backward: 119.22358007700582\n",
      "20.  act_data_pkt_fwd: 127.86822541571262\n",
      "21. FIN Flag Count: 152.16124567478806\n",
      "22. Total Length of Fwd Packets: 172.717240631204\n",
      "23.  Subflow Fwd Bytes: 172.717240631204\n",
      "24.  ACK Flag Count: 176.28001974489948\n",
      "25. Active Mean: 205.05607524167073\n",
      "26. Fwd PSH Flags: 223.7051754746605\n",
      "27.  SYN Flag Count: 223.7051754746605\n",
      "28.  Flow Duration: 233.05483395096692\n",
      "29.  Active Max: 382.02744872669155\n",
      "30.  Active Std: 393.8748800478455\n",
      "31. Fwd IAT Total: 472.5559894435117\n",
      "32.  Source Port: 478.4989558578347\n",
      "33.  PSH Flag Count: 608.7286594099377\n",
      "34. Init_Win_bytes_forward: 645.4941831854316\n",
      "35.  URG Flag Count: 991.1392777430855\n",
      "36.  Destination Port: 2887.3174133004654\n"
     ]
    }
   ],
   "source": [
    "# 특성들의 가중치(Chi-square 통계량) 확인\n",
    "chi2_scores = selector.scores_[selected_feature_indices]\n",
    "\n",
    "# 특성들의 가중치를 기준으로 오름차순 정렬\n",
    "sorted_indices = chi2_scores.argsort()\n",
    "sorted_features = selected_feature_names[sorted_indices]\n",
    "sorted_chi2_scores = chi2_scores[sorted_indices]\n",
    "\n",
    "# 특성들의 가중치와 순위 출력\n",
    "print(\"특성들의 순위와 가중치:\")\n",
    "for i, (feature, score) in enumerate(zip(sorted_features, sorted_chi2_scores), 1):\n",
    "    print(f\"{i}. {feature}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_benign_subset의 샘플 개수: 160000\n"
     ]
    }
   ],
   "source": [
    "# 'Benign' 클래스의 파일 경로 리스트 받아오기\n",
    "benign_file_paths = glob.glob(benign_folder_path + '/*.csv')\n",
    "\n",
    "# 'Benign' 클래스의 데이터프레임 초기화\n",
    "benign_data = pd.DataFrame()\n",
    "\n",
    "# 'Benign' 클래스의 모든 파일 로드\n",
    "for file_path in benign_file_paths:\n",
    "    data = pd.read_csv(file_path)\n",
    "    benign_data = pd.concat([benign_data, data], ignore_index=True)\n",
    "\n",
    "# 'Benign' 클래스에서 160,000개 무작위 샘플 추출\n",
    "num_samples_benign = 160000\n",
    "if len(benign_data) > num_samples_benign:\n",
    "    benign_subset = benign_data.sample(n=num_samples_benign, random_state=42)\n",
    "else:\n",
    "    benign_subset = benign_data.copy()\n",
    "\n",
    "print(\"train_benign_subset의 샘플 개수:\", len(benign_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ransomware_subset의 샘플 개수: 40000\n"
     ]
    }
   ],
   "source": [
    "# 각 랜섬웨어 클래스별로 4000개씩 무작위 샘플 추출 (비복원 추출)\n",
    "num_samples_per_ransomware_class = 4000\n",
    "all_ransomware_data = []\n",
    "\n",
    "# Ransomware 폴더 내의 10개 폴더 경로 리스트 받아오기\n",
    "ransomware_folder_list = glob.glob(folder_path + '\\\\Ransomware\\\\*')\n",
    "\n",
    "for ransomware_folder_path in ransomware_folder_list:\n",
    "    ransomware_file_paths = glob.glob(ransomware_folder_path + '/*.csv')\n",
    "    ransomware_data = pd.DataFrame()\n",
    "\n",
    "    # 각 랜섬웨어 클래스의 모든 파일 로드\n",
    "    for file_path in ransomware_file_paths:\n",
    "        data = pd.read_csv(file_path)\n",
    "        ransomware_data = pd.concat([ransomware_data, data], ignore_index=True)\n",
    "\n",
    "    # 랜섬웨어 클래스에서 4000개 무작위 샘플 추출 (비복원 추출)\n",
    "    if len(ransomware_data) > num_samples_per_ransomware_class:\n",
    "        ransomware_subset = ransomware_data.sample(n=num_samples_per_ransomware_class, random_state=42, replace=False)\n",
    "    else:\n",
    "        ransomware_subset = ransomware_data.copy()\n",
    "    all_ransomware_data.append(ransomware_subset)\n",
    "\n",
    "# 모든 랜섬웨어 클래스의 데이터프레임들을 합치기\n",
    "all_ransomware_data_subset = pd.concat(all_ransomware_data, ignore_index=True)\n",
    "\n",
    "print(\"ransomware_subset의 샘플 개수:\", len(all_ransomware_data_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 train 데이터세트의 샘플 개수: 200000\n"
     ]
    }
   ],
   "source": [
    "# 'Benign' 클래스와 랜섬웨어 클래스의 데이터프레임들을 합치기\n",
    "sub_dataset = pd.concat([benign_subset, all_ransomware_data_subset], ignore_index=True)\n",
    "\n",
    "print(\"최종 train 데이터세트의 샘플 개수:\", len(sub_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화된 특성들의 데이터프레임:\n",
      "    Source Port   Destination Port   Flow Duration  \\\n",
      "0      0.592166           0.000811        0.000794   \n",
      "1      0.758065           0.001224        0.002154   \n",
      "2      0.564211           0.006779        0.085388   \n",
      "3      0.739433           0.001224        0.004174   \n",
      "4      0.720954           0.006779        0.024747   \n",
      "\n",
      "   Total Length of Fwd Packets   Fwd Packet Length Max  \\\n",
      "0                     0.000004                0.001924   \n",
      "1                     0.000000                0.000000   \n",
      "2                     0.000058                0.025503   \n",
      "3                     0.000101                0.048244   \n",
      "4                     0.000005                0.001135   \n",
      "\n",
      "    Bwd Packet Length Mean   Bwd Packet Length Std   Flow IAT Mean  \\\n",
      "0                 0.070548                0.000000        0.000795   \n",
      "1                 0.000000                0.000000        0.002155   \n",
      "2                 0.025616                0.062627        0.009495   \n",
      "3                 0.089212                0.241179        0.000696   \n",
      "4                 0.000000                0.000000        0.024767   \n",
      "\n",
      "    Flow IAT Max   Flow IAT Min  ...   Init_Win_bytes_backward  \\\n",
      "0       0.000795   7.950618e-04  ...                  0.000000   \n",
      "1       0.002155   2.155394e-03  ...                  0.002106   \n",
      "2       0.084188   1.884902e-06  ...                  0.000916   \n",
      "3       0.002113   3.002499e-07  ...                  1.000000   \n",
      "4       0.024767   2.476759e-02  ...                  0.000000   \n",
      "\n",
      "    act_data_pkt_fwd  Active Mean   Active Std   Active Max   Active Min  \\\n",
      "0           0.000000     0.000000          0.0     0.000000     0.000000   \n",
      "1           0.000000     0.000000          0.0     0.000000     0.000000   \n",
      "2           0.000297     0.001415          0.0     0.001415     0.001415   \n",
      "3           0.000149     0.000000          0.0     0.000000     0.000000   \n",
      "4           0.000149     0.000000          0.0     0.000000     0.000000   \n",
      "\n",
      "   Idle Mean   Idle Std   Idle Max   Idle Min  \n",
      "0   0.000000        0.0   0.000000   0.000000  \n",
      "1   0.000000        0.0   0.000000   0.000000  \n",
      "2   0.084263        0.0   0.084263   0.084263  \n",
      "3   0.000000        0.0   0.000000   0.000000  \n",
      "4   0.000000        0.0   0.000000   0.000000  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 선택된 36가지 특성에 해당하는 열만 추출\n",
    "selected_feature_columns = X_final.columns\n",
    "selected_feature_values = sub_dataset[selected_feature_columns]\n",
    "\n",
    "# Min-Max 스케일링을 사용하여 선택된 특성들을 0과 1 사이의 값으로 정규화 > normalization으로 쓰기\n",
    "scaler = MinMaxScaler()\n",
    "selected_feature_values_normalized = scaler.fit_transform(selected_feature_values)\n",
    "\n",
    "# 정규화된 특성들을 데이터프레임으로 변환\n",
    "X_final_normalized = pd.DataFrame(selected_feature_values_normalized, columns=selected_feature_columns)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"정규화된 특성들의 데이터프레임:\")\n",
    "print(X_final_normalized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6x6 크기의 2차원 행렬:\n",
      "[[5.92165899e-01 8.11005187e-04 7.94301774e-04 4.00783933e-06\n",
      "  1.92383583e-03 7.05479452e-02]\n",
      " [0.00000000e+00 7.94961759e-04 7.94961759e-04 7.95061763e-04\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 7.05479452e-02]\n",
      " [4.00783933e-06 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# 선택된 36가지 특성을 6x6 크기의 2차원 행렬로 변환\n",
    "num_rows = 6\n",
    "num_columns = 6\n",
    "X_final_reshaped = X_final_normalized.values.reshape(-1, num_rows, num_columns)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"6x6 크기의 2차원 행렬:\")\n",
    "print(X_final_reshaped[0])  # 첫 번째 샘플에 해당하는 6x6 행렬 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 변환 및 저장이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# 이미지를 저장할 폴더를 생성합니다.\n",
    "save_folder = r'C:\\Users\\pc\\Desktop\\CNN\\Train_Image\\\\'\n",
    "os.makedirs(os.path.join(save_folder, \"Benign\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(save_folder, \"Ransomware\"), exist_ok=True)\n",
    "\n",
    "# X_final_reshaped를 이미지로 변환하여 저장합니다.\n",
    "num_samples = X_final_reshaped.shape[0]\n",
    "for i in range(num_samples):\n",
    "    # 1채널 16비트 PNG 이미지 생성\n",
    "    image_data = X_final_reshaped[i]\n",
    "    image_data = (image_data * 65535).astype('uint16')  # 16비트로 변환\n",
    "    image = Image.fromarray(image_data, 'I;16')  # 16비트 단일 채널 이미지로 변환\n",
    "\n",
    "    # 이미지의 라벨에 따라서 저장 위치 및 파일명 설정\n",
    "    if i < 160000:\n",
    "        label = \"Benign\"\n",
    "    else:\n",
    "        label = \"Ransomware\"\n",
    "\n",
    "    image_filename = f\"image_{i}.png\"\n",
    "    image_filepath = os.path.join(save_folder, label, image_filename)\n",
    "\n",
    "    # 해당 경로에 이미지가 이미 존재하는 경우 건너뛴다.\n",
    "    if os.path.exists(image_filepath):\n",
    "        continue\n",
    "\n",
    "    image.save(image_filepath)\n",
    "\n",
    "print(\"이미지 변환 및 저장이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 이미지 데이터를 저장한 폴더 경로\n",
    "image_folder = r'C:\\Users\\pc\\Desktop\\CNN\\Train_Image\\\\'\n",
    "\n",
    "# 이미지 데이터를 불러오고 라벨을 지정합니다.\n",
    "X_data = []\n",
    "y_labels = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    if i < 160000:\n",
    "        label = 0  # Benign 클래스\n",
    "    else:\n",
    "        label = 1  # Ransomware 클래스\n",
    "\n",
    "    image_path = os.path.join(image_folder, f\"image_{i}.png\")\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # 이미지를 그레이스케일로 불러옵니다.\n",
    "    X_data.append(image)\n",
    "    y_labels.append(label)\n",
    "\n",
    "X_data = np.array(X_data)\n",
    "y_labels = np.array(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Benign samples: 160000\n",
      "Number of Ransomware samples: 40000\n"
     ]
    }
   ],
   "source": [
    "# Count the number of samples in each class\n",
    "num_benign_samples = np.count_nonzero(y_labels == 0)\n",
    "num_ransomware_samples = np.count_nonzero(y_labels == 1)\n",
    "\n",
    "print(\"Number of Benign samples:\", num_benign_samples)\n",
    "print(\"Number of Ransomware samples:\", num_ransomware_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존에 train 데이터셋으로 사용된 인덱스를 추출\n",
    "train_benign_indices = benign_subset.index\n",
    "train_ransomware_indices = all_ransomware_data_subset.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation_benign_subset의 샘플 개수: 20000\n"
     ]
    }
   ],
   "source": [
    "# 사용되지 않은 benign 데이터에서 추가로 20,000개 추출\n",
    "remaining_benign_data = benign_data.drop(train_benign_indices)\n",
    "num_samples_val_benign = 20000\n",
    "if len(remaining_benign_data) > num_samples_val_benign:\n",
    "    val_benign_subset = remaining_benign_data.sample(n=num_samples_val_benign, random_state=42)\n",
    "else:\n",
    "    val_benign_subset = remaining_benign_data.copy()\n",
    "\n",
    "print(\"Validation_benign_subset의 샘플 개수:\", len(val_benign_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation_ransomware_subset의 샘플 개수: 1200\n"
     ]
    }
   ],
   "source": [
    "num_samples_additional = 400\n",
    "val_ransomware_subset = []\n",
    "\n",
    "for ransomware_folder_path in ransomware_folder_list:\n",
    "    ransomware_file_paths = glob.glob(ransomware_folder_path + '/*.csv')\n",
    "    ransomware_data = pd.DataFrame()\n",
    "\n",
    "    # 각 랜섬웨어 클래스의 모든 파일 로드\n",
    "    for file_path in ransomware_file_paths:\n",
    "        data = pd.read_csv(file_path)\n",
    "        ransomware_data = pd.concat([ransomware_data, data], ignore_index=True)\n",
    "\n",
    "    # 이미 선택된 샘플들 제외\n",
    "    remaining_data = ransomware_data.drop(train_ransomware_indices, errors='ignore')\n",
    "\n",
    "    # 400개의 샘플 추출\n",
    "    if len(remaining_data) > num_samples_additional:\n",
    "        subset = remaining_data.sample(n=num_samples_additional, random_state=42)\n",
    "    else:\n",
    "        subset = remaining_data.copy()\n",
    "    \n",
    "    val_ransomware_subset.append(subset)\n",
    "\n",
    "# 모든 추가된 랜섬웨어 데이터의 데이터프레임들을 합치기\n",
    "val_ransomware_subset = pd.concat(val_ransomware_subset, ignore_index=True)\n",
    "\n",
    "print(\"Validation_ransomware_subset의 샘플 개수:\", len(val_ransomware_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Validation 데이터세트의 샘플 개수: 21200\n"
     ]
    }
   ],
   "source": [
    "# 'Benign' 클래스와 랜섬웨어 클래스의 데이터프레임들을 합치기\n",
    "val_sub_dataset = pd.concat([val_benign_subset, val_ransomware_subset], ignore_index=True)\n",
    "\n",
    "print(\"최종 Validation 데이터세트의 샘플 개수:\", len(val_sub_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Validation 데이터세트의 샘플 개수: 21200\n"
     ]
    }
   ],
   "source": [
    "# 'Benign' 클래스와 랜섬웨어 클래스의 데이터프레임들을 합치기\n",
    "val_sub_dataset = pd.concat([val_benign_subset, val_ransomware_subset], ignore_index=True)\n",
    "\n",
    "print(\"최종 Validation 데이터세트의 샘플 개수:\", len(val_sub_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택된 36가지 특성에 해당하는 열만 추출 (Validation 데이터셋)\n",
    "val_selected_feature_values = val_sub_dataset[selected_feature_columns]\n",
    "\n",
    "# Min-Max 스케일링을 사용하여 선택된 특성들을 0과 1 사이의 값으로 정규화 (Validation 데이터셋)\n",
    "val_selected_feature_values_normalized = scaler.transform(val_selected_feature_values)\n",
    "\n",
    "# 정규화된 특성들을 데이터프레임으로 변환 (Validation 데이터셋)\n",
    "X_val_normalized = pd.DataFrame(val_selected_feature_values_normalized, columns=selected_feature_columns)\n",
    "\n",
    "# 선택된 36가지 특성을 6x6 크기의 2차원 행렬로 변환 (Validation 데이터셋)\n",
    "X_val_reshaped = X_val_normalized.values.reshape(-1, num_rows, num_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation 이미지 변환 및 저장이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 이미지를 저장할 폴더를 생성합니다.\n",
    "val_save_folder = r'C:\\Users\\pc\\Desktop\\CNN\\Validation_Image\\\\'\n",
    "os.makedirs(os.path.join(val_save_folder, \"Benign\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(val_save_folder, \"Ransomware\"), exist_ok=True)\n",
    "\n",
    "# X_val_reshaped를 이미지로 변환하여 저장합니다.\n",
    "num_val_samples = X_val_reshaped.shape[0]\n",
    "for i in range(num_val_samples):\n",
    "    # 1채널 16비트 PNG 이미지 생성\n",
    "    image_data = X_val_reshaped[i]\n",
    "    image_data = (image_data * 65535).astype('uint16')  # 16비트로 변환\n",
    "    image = Image.fromarray(image_data, 'I;16')  # 16비트 단일 채널 이미지로 변환\n",
    "\n",
    "    # 이미지의 라벨에 따라서 저장 위치 및 파일명 설정\n",
    "    if i < num_samples_val_benign:\n",
    "        label = \"Benign\"\n",
    "    else:\n",
    "        label = \"Ransomware\"\n",
    "\n",
    "    image_filename = f\"image_{i}.png\"\n",
    "    image.save(os.path.join(val_save_folder, label, image_filename))\n",
    "\n",
    "print(\"Validation 이미지 변환 및 저장이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_benign_subset의 샘플 개수: 20000\n"
     ]
    }
   ],
   "source": [
    "benign_folder_path = r'C:\\Users\\pc\\Desktop\\CNN\\CIC-AndMal2017\\Benign'\n",
    "\n",
    "# 'Benign' 클래스의 파일 경로 리스트 받아오기\n",
    "test_benign_file_paths = glob.glob(benign_folder_path + '/*.csv')\n",
    "\n",
    "# 'Benign' 클래스의 데이터프레임 초기화\n",
    "test_benign_data = pd.DataFrame()\n",
    "\n",
    "# 'Benign' 클래스의 모든 파일 로드\n",
    "for file_path in test_benign_file_paths:\n",
    "    data = pd.read_csv(file_path)\n",
    "    test_benign_data = pd.concat([test_benign_data, data], ignore_index=True)\n",
    "\n",
    "# 'Benign' 클래스에서 20,000개 무작위 샘플 추출 (Test 데이터셋)\n",
    "num_samples_test_benign = 20000\n",
    "if len(test_benign_data) > num_samples_test_benign:\n",
    "    test_benign_subset = test_benign_data.sample(n=num_samples_test_benign, random_state=42)\n",
    "else:\n",
    "    test_benign_subset = test_benign_data.copy()\n",
    "\n",
    "print(\"test_benign_subset의 샘플 개수:\", len(test_benign_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ransomware_subset의 샘플 개수: 4000\n"
     ]
    }
   ],
   "source": [
    "# 각 랜섬웨어 클래스별로 400개씩 무작위 샘플 추출 (비복원 추출)\n",
    "num_samples_per_ransomware_class = 400\n",
    "all_ransomware_data = []\n",
    "\n",
    "# Ransomware 폴더 내의 10개 폴더 경로 리스트 받아오기\n",
    "ransomware_folder_list = glob.glob(folder_path + '\\\\Ransomware\\\\*')\n",
    "\n",
    "for ransomware_folder_path in ransomware_folder_list:\n",
    "    ransomware_file_paths = glob.glob(ransomware_folder_path + '/*.csv')\n",
    "    ransomware_data = pd.DataFrame()\n",
    "\n",
    "    # 각 랜섬웨어 클래스의 모든 파일 로드\n",
    "    for file_path in ransomware_file_paths:\n",
    "        data = pd.read_csv(file_path)\n",
    "        ransomware_data = pd.concat([ransomware_data, data], ignore_index=True)\n",
    "\n",
    "    # 랜섬웨어 클래스에서 400개 무작위 샘플 추출 (비복원 추출)\n",
    "    if len(ransomware_data) > num_samples_per_ransomware_class:\n",
    "        ransomware_subset = ransomware_data.sample(n=num_samples_per_ransomware_class, random_state=42, replace=False)\n",
    "    else:\n",
    "        ransomware_subset = ransomware_data.copy()\n",
    "    all_ransomware_data.append(ransomware_subset)\n",
    "\n",
    "# 모든 랜섬웨어 클래스의 데이터프레임들을 합치기\n",
    "all_test_ransomware_data_subset = pd.concat(all_ransomware_data, ignore_index=True)\n",
    "\n",
    "print(\"ransomware_subset의 샘플 개수:\", len(all_test_ransomware_data_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Test 서브 데이터세트의 샘플 개수: 24000\n"
     ]
    }
   ],
   "source": [
    "# 'Benign' 클래스와 랜섬웨어 클래스의 데이터프레임들을 합치기 (Test 데이터셋)\n",
    "test_sub_dataset = pd.concat([test_benign_subset, all_test_ransomware_data_subset], ignore_index=True)\n",
    "\n",
    "print(\"최종 Test 서브 데이터세트의 샘플 개수:\", len(test_sub_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택된 36가지 특성에 해당하는 열만 추출 (Test 데이터셋)\n",
    "test_selected_feature_values = test_sub_dataset[selected_feature_columns]\n",
    "\n",
    "# Min-Max 스케일링을 사용하여 선택된 특성들을 0과 1 사이의 값으로 정규화 (Test 데이터셋)\n",
    "test_selected_feature_values_normalized = scaler.transform(test_selected_feature_values)\n",
    "\n",
    "# 정규화된 특성들을 데이터프레임으로 변환 (Test 데이터셋)\n",
    "X_test_normalized = pd.DataFrame(test_selected_feature_values_normalized, columns=selected_feature_columns)\n",
    "\n",
    "# 선택된 36가지 특성을 6x6 크기의 2차원 행렬로 변환 (Test 데이터셋)\n",
    "X_test_reshaped = X_test_normalized.values.reshape(-1, num_rows, num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 이미지 변환 및 저장이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 이미지를 저장할 폴더를 생성합니다.\n",
    "test_save_folder = r'C:\\Users\\pc\\Desktop\\CNN\\Test_Image\\\\'\n",
    "os.makedirs(os.path.join(test_save_folder, \"Benign\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(test_save_folder, \"Ransomware\"), exist_ok=True)\n",
    "\n",
    "# X_test_reshaped를 이미지로 변환하여 저장합니다.\n",
    "num_test_samples = X_test_reshaped.shape[0]\n",
    "for i in range(num_test_samples):\n",
    "    # 이미지의 라벨에 따라서 저장 위치 및 파일명 설정\n",
    "    if i < num_samples_test_benign:\n",
    "        label = \"Benign\"\n",
    "    else:\n",
    "        label = \"Ransomware\"\n",
    "\n",
    "    image_filename = f\"image_{i}.png\"\n",
    "    image_path = os.path.join(test_save_folder, label, image_filename)\n",
    "    \n",
    "    # 이미 해당 경로에 이미지가 있다면, 저장하지 않고 넘어갑니다.\n",
    "    if os.path.exists(image_path):\n",
    "        continue\n",
    "\n",
    "    # 1채널 16비트 PNG 이미지 생성\n",
    "    image_data = X_test_reshaped[i]\n",
    "    image_data = (image_data * 65535).astype('uint16')  # 16비트로 변환\n",
    "    image = Image.fromarray(image_data, 'I;16')  # 16비트 단일 채널 이미지로 변환\n",
    "    \n",
    "    image.save(image_path)\n",
    "    \n",
    "print(\"Test 이미지 변환 및 저장이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Convolution 1\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Maxpooling 1\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Convolution 2\n",
    "    model.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Maxpooling 2\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Convolution 3\n",
    "    model.add(layers.Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Maxpooling 3\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Flatten\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # FC 1\n",
    "    model.add(layers.Dense(2048, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    # FC 2\n",
    "    model.add(layers.Dense(2048, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    # FC 3 (출력층)\n",
    "    model.add(layers.Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200000 images belonging to 2 classes.\n",
      "Found 24000 images belonging to 2 classes.\n",
      "Found 24000 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      " 648/6250 [==>...........................] - ETA: 7:42 - loss: 0.5384 - accuracy: 0.7971 - auc: 0.5080"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39m# 모델 학습\u001b[39;00m\n\u001b[0;32m     50\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m\n\u001b[1;32m---> 51\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_generator, epochs\u001b[39m=\u001b[39;49mepochs, validation_data\u001b[39m=\u001b[39;49mval_generator)\n\u001b[0;32m     53\u001b[0m \u001b[39m# 모델 평가\u001b[39;00m\n\u001b[0;32m     54\u001b[0m test_loss, test_accuracy, test_auc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(test_generator)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\engine\\training.py:1691\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1689\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[0;32m   1690\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[1;32m-> 1691\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[0;32m   1692\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[0;32m   1693\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \n\u001b[0;32m    470\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 475\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    321\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 322\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[0;32m    323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    324\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    325\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    326\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    327\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[0;32m    343\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 345\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    348\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m    392\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 393\u001b[0m     hook(batch, logs)\n\u001b[0;32m    395\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[0;32m    396\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1093\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\callbacks.py:1170\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1167\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1168\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m   1169\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m-> 1170\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprogbar\u001b[39m.\u001b[39;49mupdate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseen, \u001b[39mlist\u001b[39;49m(logs\u001b[39m.\u001b[39;49mitems()), finalize\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\utils\\generic_utils.py:296\u001b[0m, in \u001b[0;36mProgbar.update\u001b[1;34m(self, current, values, finalize)\u001b[0m\n\u001b[0;32m    293\u001b[0m         info \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    295\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m info\n\u001b[1;32m--> 296\u001b[0m     io_utils\u001b[39m.\u001b[39;49mprint_msg(message, line_break\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    297\u001b[0m     message \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    299\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\utils\\io_utils.py:80\u001b[0m, in \u001b[0;36mprint_msg\u001b[1;34m(message, line_break)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mwrite(message)\n\u001b[1;32m---> 80\u001b[0m     sys\u001b[39m.\u001b[39;49mstdout\u001b[39m.\u001b[39;49mflush()\n\u001b[0;32m     81\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m     logging\u001b[39m.\u001b[39minfo(message)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\iostream.py:521\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"trigger actual zmq send\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \n\u001b[0;32m    512\u001b[0m \u001b[39msend will happen in the background thread\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    515\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpub_thread\n\u001b[0;32m    516\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpub_thread\u001b[39m.\u001b[39mthread \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m ):\n\u001b[0;32m    520\u001b[0m     \u001b[39m# request flush on the background thread\u001b[39;00m\n\u001b[1;32m--> 521\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpub_thread\u001b[39m.\u001b[39;49mschedule(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flush)\n\u001b[0;32m    522\u001b[0m     \u001b[39m# wait for flush to actually get through, if we can.\u001b[39;00m\n\u001b[0;32m    523\u001b[0m     evt \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mEvent()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel\\iostream.py:213\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_events\u001b[39m.\u001b[39mappend(f)\n\u001b[0;32m    212\u001b[0m     \u001b[39m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event_pipe\u001b[39m.\u001b[39;49msend(\u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     f()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\zmq\\sugar\\socket.py:620\u001b[0m, in \u001b[0;36mSocket.send\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    613\u001b[0m         data \u001b[39m=\u001b[39m zmq\u001b[39m.\u001b[39mFrame(\n\u001b[0;32m    614\u001b[0m             data,\n\u001b[0;32m    615\u001b[0m             track\u001b[39m=\u001b[39mtrack,\n\u001b[0;32m    616\u001b[0m             copy\u001b[39m=\u001b[39mcopy \u001b[39mor\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    617\u001b[0m             copy_threshold\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy_threshold,\n\u001b[0;32m    618\u001b[0m         )\n\u001b[0;32m    619\u001b[0m     data\u001b[39m.\u001b[39mgroup \u001b[39m=\u001b[39m group\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msend(data, flags\u001b[39m=\u001b[39;49mflags, copy\u001b[39m=\u001b[39;49mcopy, track\u001b[39m=\u001b[39;49mtrack)\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:746\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:793\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:250\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\zmq\\backend\\cython\\checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 이미지 데이터 폴더 경로\n",
    "train_data_folder = r'C:\\Users\\pc\\Desktop\\CNN\\Train_Image'\n",
    "val_data_folder = r'C:\\Users\\pc\\Desktop\\CNN\\Validation_Image'\n",
    "test_data_folder = r'C:\\Users\\pc\\Desktop\\CNN\\Test_Image'\n",
    "\n",
    "# 모델 생성\n",
    "input_shape = (28, 28, 1)  # 입력 이미지의 크기와 채널 수\n",
    "num_classes = 1  # 이진 분류 문제의 경우 클래스 개수는 1\n",
    "model = create_model(input_shape, num_classes)\n",
    "\n",
    "# ImageDataGenerator 생성\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 학습 데이터 로드\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_data_folder,\n",
    "    target_size=(28, 28),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Validation 데이터 로드\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    val_data_folder,\n",
    "    target_size=(28, 28),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=False  # Validation 데이터는 섞지 않음\n",
    ")\n",
    "\n",
    "# Test 데이터 로드\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_data_folder,\n",
    "    target_size=(28, 28),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=False  # Test 데이터는 섞지 않음\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "epochs = 50\n",
    "history = model.fit(train_generator, epochs=epochs, validation_data=val_generator)\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_accuracy, test_auc = model.evaluate(test_generator)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test AUC:\", test_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
