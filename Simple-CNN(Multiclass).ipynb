{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_simple_cnn(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Convolutional layer and max pooling\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Another convolutional layer and max pooling\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Flatten the 3D output to 1D tensor\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # Fully connected layer\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_and_labels(data_folder, num_classes, img_size=(28, 28), color_mode='grayscale'):\n",
    "    X = []\n",
    "    y_onehot = []\n",
    "    \n",
    "    for idx, class_folder in enumerate(sorted(os.listdir(data_folder))):\n",
    "        class_path = os.path.join(data_folder, class_folder)\n",
    "        \n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            img = load_img(img_path, target_size=img_size, color_mode=color_mode)\n",
    "            X.append(img_to_array(img))\n",
    "            \n",
    "            onehot = np.zeros(num_classes)\n",
    "            onehot[idx] = 1\n",
    "            y_onehot.append(onehot)\n",
    "    \n",
    "    return np.array(X) / 255.0, np.array(y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1250/1250 [==============================] - 10s 7ms/step - loss: 2.3795 - accuracy: 0.1582 - auc: 0.5862 - val_loss: 2.1619 - val_accuracy: 0.1672 - val_auc: 0.6129\n",
      "Epoch 2/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.1568 - accuracy: 0.1793 - auc: 0.6230 - val_loss: 2.1339 - val_accuracy: 0.1818 - val_auc: 0.6368\n",
      "Epoch 3/50\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 2.1390 - accuracy: 0.1818 - auc: 0.6340 - val_loss: 2.1167 - val_accuracy: 0.1898 - val_auc: 0.6414\n",
      "Epoch 4/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.1254 - accuracy: 0.1874 - auc: 0.6424 - val_loss: 2.0956 - val_accuracy: 0.1920 - val_auc: 0.6577\n",
      "Epoch 5/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.1139 - accuracy: 0.1900 - auc: 0.6488 - val_loss: 2.0893 - val_accuracy: 0.1940 - val_auc: 0.6610\n",
      "Epoch 6/50\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 2.1015 - accuracy: 0.1921 - auc: 0.6561 - val_loss: 2.0815 - val_accuracy: 0.2030 - val_auc: 0.6615\n",
      "Epoch 7/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.0956 - accuracy: 0.1962 - auc: 0.6577 - val_loss: 2.0788 - val_accuracy: 0.2018 - val_auc: 0.6674\n",
      "Epoch 8/50\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 2.0857 - accuracy: 0.1979 - auc: 0.6631 - val_loss: 2.0664 - val_accuracy: 0.2026 - val_auc: 0.6735\n",
      "Epoch 9/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.0789 - accuracy: 0.2009 - auc: 0.6670 - val_loss: 2.0567 - val_accuracy: 0.2114 - val_auc: 0.6767\n",
      "Epoch 10/50\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 2.0691 - accuracy: 0.2070 - auc: 0.6720 - val_loss: 2.0561 - val_accuracy: 0.2086 - val_auc: 0.6775\n",
      "Epoch 11/50\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 2.0622 - accuracy: 0.2088 - auc: 0.6756 - val_loss: 2.0520 - val_accuracy: 0.2210 - val_auc: 0.6797\n",
      "Epoch 12/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.0553 - accuracy: 0.2101 - auc: 0.6796 - val_loss: 2.0449 - val_accuracy: 0.2144 - val_auc: 0.6873\n",
      "Epoch 13/50\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 2.0494 - accuracy: 0.2125 - auc: 0.6834 - val_loss: 2.0261 - val_accuracy: 0.2206 - val_auc: 0.6927\n",
      "Epoch 14/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.0413 - accuracy: 0.2138 - auc: 0.6867 - val_loss: 2.0262 - val_accuracy: 0.2180 - val_auc: 0.6917\n",
      "Epoch 15/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.0349 - accuracy: 0.2182 - auc: 0.6903 - val_loss: 2.0225 - val_accuracy: 0.2188 - val_auc: 0.6942\n",
      "Epoch 16/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.0299 - accuracy: 0.2194 - auc: 0.6927 - val_loss: 2.0179 - val_accuracy: 0.2204 - val_auc: 0.6969\n",
      "Epoch 17/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.0246 - accuracy: 0.2200 - auc: 0.6952 - val_loss: 2.0106 - val_accuracy: 0.2254 - val_auc: 0.6998\n",
      "Epoch 18/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.0196 - accuracy: 0.2218 - auc: 0.6970 - val_loss: 2.0207 - val_accuracy: 0.2222 - val_auc: 0.6946\n",
      "Epoch 19/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.0167 - accuracy: 0.2237 - auc: 0.6993 - val_loss: 2.0081 - val_accuracy: 0.2316 - val_auc: 0.7020\n",
      "Epoch 20/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.0119 - accuracy: 0.2246 - auc: 0.7009 - val_loss: 2.0020 - val_accuracy: 0.2352 - val_auc: 0.7030\n",
      "Epoch 21/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.0074 - accuracy: 0.2271 - auc: 0.7034 - val_loss: 1.9950 - val_accuracy: 0.2344 - val_auc: 0.7070\n",
      "Epoch 22/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 2.0021 - accuracy: 0.2293 - auc: 0.7061 - val_loss: 1.9857 - val_accuracy: 0.2394 - val_auc: 0.7108\n",
      "Epoch 23/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9936 - accuracy: 0.2327 - auc: 0.7085 - val_loss: 1.9820 - val_accuracy: 0.2398 - val_auc: 0.7113\n",
      "Epoch 24/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9868 - accuracy: 0.2342 - auc: 0.7123 - val_loss: 1.9727 - val_accuracy: 0.2406 - val_auc: 0.7159\n",
      "Epoch 25/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9829 - accuracy: 0.2340 - auc: 0.7128 - val_loss: 1.9661 - val_accuracy: 0.2440 - val_auc: 0.7206\n",
      "Epoch 26/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9774 - accuracy: 0.2364 - auc: 0.7154 - val_loss: 1.9637 - val_accuracy: 0.2456 - val_auc: 0.7208\n",
      "Epoch 27/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9716 - accuracy: 0.2369 - auc: 0.7178 - val_loss: 1.9658 - val_accuracy: 0.2474 - val_auc: 0.7207\n",
      "Epoch 28/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9690 - accuracy: 0.2407 - auc: 0.7192 - val_loss: 1.9579 - val_accuracy: 0.2474 - val_auc: 0.7232\n",
      "Epoch 29/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9635 - accuracy: 0.2415 - auc: 0.7213 - val_loss: 1.9575 - val_accuracy: 0.2486 - val_auc: 0.7242\n",
      "Epoch 30/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9600 - accuracy: 0.2437 - auc: 0.7231 - val_loss: 1.9539 - val_accuracy: 0.2476 - val_auc: 0.7270\n",
      "Epoch 31/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9563 - accuracy: 0.2446 - auc: 0.7243 - val_loss: 1.9396 - val_accuracy: 0.2572 - val_auc: 0.7311\n",
      "Epoch 32/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9526 - accuracy: 0.2451 - auc: 0.7256 - val_loss: 1.9389 - val_accuracy: 0.2496 - val_auc: 0.7313\n",
      "Epoch 33/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9511 - accuracy: 0.2465 - auc: 0.7268 - val_loss: 1.9310 - val_accuracy: 0.2512 - val_auc: 0.7333\n",
      "Epoch 34/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9465 - accuracy: 0.2493 - auc: 0.7281 - val_loss: 1.9407 - val_accuracy: 0.2542 - val_auc: 0.7296\n",
      "Epoch 35/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9438 - accuracy: 0.2492 - auc: 0.7293 - val_loss: 1.9288 - val_accuracy: 0.2526 - val_auc: 0.7336\n",
      "Epoch 36/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9384 - accuracy: 0.2500 - auc: 0.7314 - val_loss: 1.9341 - val_accuracy: 0.2488 - val_auc: 0.7329\n",
      "Epoch 37/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9388 - accuracy: 0.2494 - auc: 0.7311 - val_loss: 1.9233 - val_accuracy: 0.2626 - val_auc: 0.7370\n",
      "Epoch 38/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9367 - accuracy: 0.2511 - auc: 0.7327 - val_loss: 1.9272 - val_accuracy: 0.2576 - val_auc: 0.7360\n",
      "Epoch 39/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9331 - accuracy: 0.2533 - auc: 0.7330 - val_loss: 1.9244 - val_accuracy: 0.2570 - val_auc: 0.7366\n",
      "Epoch 40/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9313 - accuracy: 0.2518 - auc: 0.7342 - val_loss: 1.9175 - val_accuracy: 0.2572 - val_auc: 0.7406\n",
      "Epoch 41/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9280 - accuracy: 0.2536 - auc: 0.7358 - val_loss: 1.9156 - val_accuracy: 0.2558 - val_auc: 0.7395\n",
      "Epoch 42/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9256 - accuracy: 0.2569 - auc: 0.7364 - val_loss: 1.9080 - val_accuracy: 0.2602 - val_auc: 0.7405\n",
      "Epoch 43/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9228 - accuracy: 0.2567 - auc: 0.7368 - val_loss: 1.9114 - val_accuracy: 0.2574 - val_auc: 0.7410\n",
      "Epoch 44/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9206 - accuracy: 0.2600 - auc: 0.7387 - val_loss: 1.9019 - val_accuracy: 0.2658 - val_auc: 0.7455\n",
      "Epoch 45/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9181 - accuracy: 0.2582 - auc: 0.7391 - val_loss: 1.9038 - val_accuracy: 0.2654 - val_auc: 0.7460\n",
      "Epoch 46/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9178 - accuracy: 0.2569 - auc: 0.7399 - val_loss: 1.9034 - val_accuracy: 0.2608 - val_auc: 0.7446\n",
      "Epoch 47/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9157 - accuracy: 0.2582 - auc: 0.7404 - val_loss: 1.8976 - val_accuracy: 0.2690 - val_auc: 0.7467\n",
      "Epoch 48/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9140 - accuracy: 0.2594 - auc: 0.7413 - val_loss: 1.8940 - val_accuracy: 0.2694 - val_auc: 0.7472\n",
      "Epoch 49/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9101 - accuracy: 0.2620 - auc: 0.7420 - val_loss: 1.9037 - val_accuracy: 0.2644 - val_auc: 0.7461\n",
      "Epoch 50/50\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.9087 - accuracy: 0.2607 - auc: 0.7426 - val_loss: 1.8917 - val_accuracy: 0.2662 - val_auc: 0.7494\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.8917 - accuracy: 0.2662 - auc: 0.7494\n",
      "Test Loss: 1.891676902770996\n",
      "Test Accuracy: 0.2662000060081482\n",
      "Test AUC: 0.749435305595398\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# 데이터 경로\n",
    "base_path = r'C:\\Users\\pc\\Desktop\\CNN'\n",
    "train_data_folder = os.path.join(base_path, 'Multiclass_Train_Image')\n",
    "val_data_folder = os.path.join(base_path, 'Multiclass_Validation_Image')\n",
    "test_data_folder = os.path.join(base_path, 'Multiclass_Test_Image')\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# 데이터 로드\n",
    "X_train, y_train_onehot = load_data_and_labels(train_data_folder, num_classes)\n",
    "X_val, y_val_onehot = load_data_and_labels(val_data_folder, num_classes)\n",
    "X_test, y_test_onehot = load_data_and_labels(test_data_folder, num_classes)\n",
    "\n",
    "# 모델 생성\n",
    "input_shape = X_train[0].shape\n",
    "model = create_simple_cnn(input_shape, num_classes)\n",
    "\n",
    "# 모델 학습\n",
    "epochs = 50\n",
    "history = model.fit(X_train, y_train_onehot, validation_data=(X_val, y_val_onehot), epochs=epochs)\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_accuracy, test_auc = model.evaluate(X_test, y_test_onehot)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test AUC:\", test_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
